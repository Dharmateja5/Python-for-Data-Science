{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Explicit data** is information that is provided intentionally, i.e. input from the users such as movie ratings\n",
    "- **Implicit data** is information that is not provided intentionally but gathered from available data streams like search history, clicks, order history, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Recommend the most popular items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recommend the items which are liked by most number of users\n",
    "- There is no personalization involved with this approach\n",
    "- Surprisingly, this approach still works in places like news portals with a column of “Popular News” which is subdivided into sections and the most read articles of each sections are displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can divide the users into multiple segments based on their preferences (user features) and recommend items to them based on the segment they belong to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: Using a classifier to make recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to define some parameters (features) of the user and the item\n",
    "- The outcome can be 1 if the user likes it or 0 otherwise\n",
    "- Incorporates personalization\n",
    "- It can work even if the user’s past history is short or not available\n",
    "- The features might actually not be available or even if they are, they may not be sufficient to make a good classifier\n",
    "- As the number of users and items grow, making a good classifier will become exponentially difficult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4: Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b> Idea: </b> If you like an item then you will also like a “similar” item\n",
    "- It generally works well when its easy to determine the context/properties of each item. For instance when we are recommending the same kind of item like a movie recommendation or song recommendation.\n",
    "- In content-based recommender systems, the descriptive attributes of items are used to make recommendations. The term “content” refers to these descriptions. In content-based methods, the ratings and buying behavior of users are combined with the content information available in the items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Content Based Filtering.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Movie Recommendation Example***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Profile vector:** It contains the past behavior of the user, i.e the movies liked/disliked by the user and the ratings given by them\n",
    "- **Item vector:** It contains the details of each movie, like genre, cast, director etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity between profile vector and item vector is calculated using following methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cosine Similarity:** Cosine of the angle between the profile vector (A) and item vector (B). Closer the vectors, smaller will be the angle and larger the cosine. The value ranges between -1 to 1.\n",
    "<img src=\"images/Cosine Similarity.jpg\">\n",
    "- **Euclidean Distance** Similar items will lie in close proximity to each other if plotted in n-dimensional space.\n",
    "<img src=\"images/Euclidean Distance.jpg\">\n",
    "- **Perason's Correlation**  It tells us how much two items are correlated.\n",
    "<img src=\"images/Correlation.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movies are arranged in descending order and one of the two below approaches is used for recommendations.\n",
    "- **Top-n approach:** Where the top n movies are recommended\n",
    "- **Rating scale approach:** Where a threshold is set and all the movies above that threshold are recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major drawback of this algorithm is that it will never recommend products which the user has not bought or liked in the past. So if a user has watched or liked only action movies in the past, the system will recommend only action movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve on this type of system, we need an algorithm that can recommend items not just based on the content, but the behavior of users as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-User collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm first finds the similarity score between users. Based on this similarity score, it then picks out the most similar users and recommends products which these similar users have liked or bought previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Images/User-User Collaborative Filtering.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the m×n ratings matrix R = $[r_{uj}]$ with m users and n items, let $I_{u}$ denote the set of item indices for which ratings have been speciﬁed by user (row) u. <br>\n",
    "Therefore, the set of items rated by both users u and v is given by $I_{u} \\cap I_{v}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ﬁrst step is to compute the mean rating $μ_{u}$ for each user u using her speciﬁed ratings\n",
    "<img src=\"Images/User Ratings Mean.jpg\">\n",
    "- Then, the Pearson correlation coeﬃcient (similarity) between the rows (users) u and v is deﬁned as follows\n",
    "<img src = \"Images/User User Similarity.jpg?123456\">\n",
    "- Similarity computation is tricky because diﬀerent users may have diﬀerent scales of ratings. One user might be biased toward liking most items, whereas another user might be biased toward not liking most of the items.  Therefore, the raw ratings need to be mean-centered in row-wise fashion\n",
    "- The Pearson coefficient is computed between the target user and all the other users. \n",
    "- One way of deﬁning the peer group of the target user would be to use the set of k users with the highest Pearson coeﬃcient with the target. \n",
    "- Since the number of observed ratings in the top-k peer group of a target user may vary signiﬁcantly with the item at hand, the closest k users are found for the target user separately for each predicted item, such that each of these k users have speciﬁed ratings for that item. \n",
    "- The weighted average of these ratings can be returned as the predicted rating for that item. Here, each rating is weighted with the Pearson correlation coefficient of its owner to the target user. \n",
    "- As before, the weighted average of the mean-centered rating of an item in the top-k peer group of target user u is used to provide a mean-centered prediction.\n",
    "- The mean rating of the target user is then added back to this prediction to provide a raw rating prediction $\\hat{r}_{uj}$ of target user u for item j. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $P_{u}(j)$ be the set of k closest users to target user u, who have speciﬁed ratings for item j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/User-User Prediction.jpg?123\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This algorithm, first of all calculates the similarity between each user based on the ratings and then based on each similarity calculates the predictions\n",
    "- Based on these prediction values, recommendations are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*User Item Matrix*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/User Item Matrix.jpg?123\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the ratings of ﬁve users 1...5 are indicated for six items denoted by 1...6. <br>\n",
    "Consider the case where target user index is 3, and we want to make item predictions on the basis of ratings in 2.1. <br>\n",
    "We need to compute $\\hat{r}_{31}$ and $\\hat{r}_{36}$ of user 3 for items 1 and 6 in order to determine the top recommended item.\n",
    "- The first step is to compute the similarity between user 3 and all the other users.\n",
    "\n",
    "<img src = \"Images/User User Similarity Example.jpg\" width=\"600\">\n",
    "\n",
    "- The top 2 closest users to user 3 are users 1 and users 2 according to both measures. \n",
    "- By using pearson weighted average of the raw ratings of users 1 and 2,the following predictions are obtained for user 3 with respect to unrated items 1 and 6\n",
    "\n",
    "<img src = \"Images/User User Prediction Example 1.jpg\" width = \"300\">\n",
    "\n",
    "- Thus, item 1 should be prioritized over item 6 as a recommendation to user 3.\n",
    "- The predicted ratings for user 3 are of very high values compared to other ratings by user 3. This is because of the peer group {1, 2} users which have very high ratings compared to user 3.\n",
    "- To avoid such scenarios, we can use mean centered ratings for prediction.\n",
    "\n",
    "<img src = \"Images/User User Prediction Example 2.jpg\" width = \"400\">\n",
    "\n",
    "-  The mean-centering process enables a much better relative prediction with respect to the ratings that have already been observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/User Item Matrix 2.jpg?123\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is quite time consuming as it involves calculating the similarity for each user and then calculating prediction for each similarity score. One way of handling this problem is to select neighbors by\n",
    "- Select a threshold similarity and choose all the users above that value\n",
    "- Randomly select the users\n",
    "- Arrange the neighbors in descending order of their similarity value and choose top-N users\n",
    "- Use clustering for choosing neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item-Item collaborative filtering\n",
    "In this algorithm, we compute the similarity between each pair of items <br>\n",
    "It is effective when the number of users is more than the items being recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Item-Item Collaborative Filtering.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In item-based collaborative filtering, peer groups are constructed in terms of items rather than users. <br>\n",
    "As in the case of user-based ratings, the average rating of each item in the ratings matrix is subtracted from each rating to create a mean-centered matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $U_{i}$ be the indices of the set of users who have specified ratings for item i. <br>\n",
    "Then the adjusted cosine similarity between the items (columns) i and j is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src = \"Images/Cosine Similarity Item Based.jpg?lastmod = 123\" width = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mean-centered ratings ($S_{ui}$) are used, similarity is called Adjusted Cosine. <br> \n",
    "Although the Pearson correlation can also be used on the columns in the case of the item-based method, the adjusted cosine generally provides superior results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case of determining rating of item t for user u.\n",
    "- The first step is to determine the top-k most similar items to item t based on the adjusted cosine similarity\n",
    "- Let the top-k matching items to item t, for which the user u as specified ratings be denoted by $Q_{t}(u)$.\n",
    "- The weighted average of these (raw) ratings is reported as the predicted value.\n",
    "- The weight of item j in this average is equal to the adjusted cosine similarity between item j and the target item t.\n",
    "- Therefore, the predicted rating $\\hat{r}_{ut}$ of user u for target item t as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/Item-Item Prediction.jpg?lastmod=12345678\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*User Item Matrix*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/User Item Matrix.jpg?123\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/User Item Matrix 2.jpg?123\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing ratings of user 3 are predicted with the item-based algorithm as the ratings of items 1 and 6 are missing for user 3, the similarity of the columns for items 1 and 6 needs to be computed with respect to the other columns (items)\n",
    "- First, the similarity between items are computed after adjusting for mean-centering.\n",
    "- The value of the adjusted cosine between items is calculated as \n",
    "\n",
    "<img src = \"Images/Item Item Similarity Example.jpg\">\n",
    "\n",
    "- It is evident that items 2 and 3 are most similar to item 1, whereas items 4 and 5 are most similar to item 6.\n",
    "- Therefore, the weighted average of raw ratings of user 3 for items 2 and 3 is used to predict the rating $\\hat{r}_{31}$ of item 1, whereas the weighted average of the raw ratings of user 3 for items 4 and 5 is used to predict the rating $/hat{r}_{36}$ of item 6:\n",
    "\n",
    "<img src = \"Images/Item Item Prediction Example 1.jpg\">\n",
    "\n",
    "- Thus, the item-based method also suggests that item 1 is more likely to be preferred by user 3 than item 6. However, in this case, because the ratings are predicted using the ratings of user 3 herself, the predicted ratings tend to be much more consistent with the other ratings of this user.\n",
    "- The greater prediction accuracy of the item-based method is its main advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cold start\n",
    "What will happen if a new user or a new item is added in the dataset?\n",
    "- Visitor Cold Start: To avoid this, we can apply a popularity based strategy. Once we know the user preferences, recommending products will be easier. \n",
    "- Product Cold Start: To avoid this, we can use the contect of the product (content based filtering) for recommendations and the eventually the user actions on the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study in Python using the MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex  occupation zip_code\n",
       "0        1   24   M  technician    85711\n",
       "1        2   53   F       other    94043\n",
       "2        3   23   M      writer    32067\n",
       "3        4   24   M  technician    43537\n",
       "4        5   33   F       other    15213"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading users file:\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('Datasets/ml-100k/u.user', sep = '|', names = u_cols, encoding = 'latin-1')\n",
    "print(users.shape)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  unix_timestamp\n",
       "0      196       242       3       881250949\n",
       "1      186       302       3       891717742\n",
       "2       22       377       1       878887116\n",
       "3      244        51       2       880606923\n",
       "4      166       346       1       886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('Datasets/ml-100k/u.data', sep = '\\t', names = r_cols, encoding = 'latin-1')\n",
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie id</th>\n",
       "      <th>movie title</th>\n",
       "      <th>release date</th>\n",
       "      <th>video release date</th>\n",
       "      <th>IMDb URL</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie id        movie title release date  video release date  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            IMDb URL  unknown  Action  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
       "\n",
       "   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
       "0          0          1           1  ...        0          0       0        0   \n",
       "1          1          0           0  ...        0          0       0        0   \n",
       "2          0          0           0  ...        0          0       0        0   \n",
       "3          0          0           0  ...        0          0       0        0   \n",
       "4          0          0           0  ...        0          0       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        0        0       0         1    0        0  \n",
       "2        0        0       0         1    0        0  \n",
       "3        0        0       0         0    0        0  \n",
       "4        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading items file:\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "items = pd.read_csv('Datasets/ml-100k/u.item', sep = '|', names = i_cols, encoding = 'latin-1')\n",
    "print(items.shape)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90570, 4), (9430, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Test sets\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('Datasets/ml-100k/ua.base', sep = '\\t', names = r_cols, encoding = 'latin-1')\n",
    "ratings_test = pd.read_csv('Datasets/ml-100k/ua.test', sep = '\\t', names = r_cols, encoding = 'latin-1')\n",
    "ratings_base.shape, ratings_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build collaborative filtering model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend movies based on user-user similarity and item-item similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique users and movies\n",
    "n_users = ratings.user_id.unique().shape[0]\n",
    "n_movies = ratings.movie_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=0, user_id=196, movie_id=242, rating=3, unix_timestamp=881250949)\n"
     ]
    }
   ],
   "source": [
    "for line in ratings.itertuples():\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-item matrix\n",
    "data_matrix = np.zeros((n_users,n_movies))\n",
    "for line in ratings.itertuples():\n",
    "    data_matrix[line[1]-1,line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., 3., 3.],\n",
       "       [4., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [4., 3., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the similarity\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(data_matrix, metric = 'cosine')\n",
    "item_similarity = pairwise_distances(data_matrix.T, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.83306902, 0.95254046, ..., 0.85138306, 0.82049212,\n",
       "        0.60182526],\n",
       "       [0.83306902, 0.        , 0.88940868, ..., 0.83851522, 0.82773219,\n",
       "        0.89420212],\n",
       "       [0.95254046, 0.88940868, 0.        , ..., 0.89875744, 0.86658385,\n",
       "        0.97344413],\n",
       "       ...,\n",
       "       [0.85138306, 0.83851522, 0.89875744, ..., 0.        , 0.8983582 ,\n",
       "        0.90488042],\n",
       "       [0.82049212, 0.82773219, 0.86658385, ..., 0.8983582 , 0.        ,\n",
       "        0.81753534],\n",
       "       [0.60182526, 0.89420212, 0.97344413, ..., 0.90488042, 0.81753534,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.59761782, 0.66975521, ..., 1.        , 0.95281693,\n",
       "        0.95281693],\n",
       "       [0.59761782, 0.        , 0.72693082, ..., 1.        , 0.92170064,\n",
       "        0.92170064],\n",
       "       [0.66975521, 0.72693082, 0.        , ..., 1.        , 1.        ,\n",
       "        0.90312495],\n",
       "       ...,\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.95281693, 0.92170064, 1.        , ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.95281693, 0.92170064, 0.90312495, ..., 1.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 943), (1682, 1682))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity.shape, item_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_user_rating = data_matrix.mean(axis = 1)\n",
    "mean_user_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_user_rating[:, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.41617122,  2.41617122,  3.41617122, ..., -0.58382878,\n",
       "        -0.58382878, -0.58382878],\n",
       "       [ 3.86325803, -0.13674197, -0.13674197, ..., -0.13674197,\n",
       "        -0.13674197, -0.13674197],\n",
       "       [-0.08977408, -0.08977408, -0.08977408, ..., -0.08977408,\n",
       "        -0.08977408, -0.08977408],\n",
       "       ...,\n",
       "       [ 4.9470868 , -0.0529132 , -0.0529132 , ..., -0.0529132 ,\n",
       "        -0.0529132 , -0.0529132 ],\n",
       "       [-0.20035672, -0.20035672, -0.20035672, ..., -0.20035672,\n",
       "        -0.20035672, -0.20035672],\n",
       "       [-0.34066587,  4.65933413, -0.34066587, ..., -0.34066587,\n",
       "        -0.34066587, -0.34066587]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix - mean_user_rating[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions\n",
    "def predict(ratings, similarity, type = 'user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis = 1)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff)/np.array([np.abs(similarity).sum(axis = 1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity)/np.array([np.abs(similarity).sum(axis = 1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prediction = predict(data_matrix, user_similarity, type = 'user')\n",
    "item_prediction = predict(data_matrix, item_similarity, type = 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.06532606,  0.73430275,  0.62992381, ...,  0.39359041,\n",
       "         0.39304874,  0.3927712 ],\n",
       "       [ 1.76308836,  0.38404019,  0.19617889, ..., -0.08837789,\n",
       "        -0.0869183 , -0.08671183],\n",
       "       [ 1.79590398,  0.32904733,  0.15882885, ..., -0.13699223,\n",
       "        -0.13496852, -0.13476488],\n",
       "       ...,\n",
       "       [ 1.59151513,  0.27526889,  0.10219534, ..., -0.16735162,\n",
       "        -0.16657451, -0.16641377],\n",
       "       [ 1.81036267,  0.40479877,  0.27545013, ..., -0.00907358,\n",
       "        -0.00846587, -0.00804858],\n",
       "       [ 1.8384313 ,  0.47964837,  0.38496292, ...,  0.14686675,\n",
       "         0.14629808,  0.14641455]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44627765, 0.475473  , 0.50593755, ..., 0.58815455, 0.5731069 ,\n",
       "        0.56669645],\n",
       "       [0.10854432, 0.13295661, 0.12558851, ..., 0.13445801, 0.13657587,\n",
       "        0.13711081],\n",
       "       [0.08568497, 0.09169006, 0.08764343, ..., 0.08465892, 0.08976784,\n",
       "        0.09084451],\n",
       "       ...,\n",
       "       [0.03230047, 0.0450241 , 0.04292449, ..., 0.05302764, 0.0519099 ,\n",
       "        0.05228033],\n",
       "       [0.15777917, 0.17409459, 0.18900003, ..., 0.19979296, 0.19739388,\n",
       "        0.20003117],\n",
       "       [0.24767207, 0.24489212, 0.28263031, ..., 0.34410424, 0.33051406,\n",
       "        0.33102478]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key idea in dimensionality reduction tehcniques is that the reduced, rotated, and compeletely specified representation can be robuslty estimated from an incomplete data matrix. <br>\n",
    "Once the completely specified representation has been obtained, one can rotate it back to the original axis system in order to obtain the fully specified representation. <br>\n",
    "Under the covers, dimensionality reduction methods leverage the row and column correlations to create the fully specified and reduced representation. <br>\n",
    "Matrix Factorization methods provide a neat way to leverage all row and column correlations in one shot to estimate the entire data matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Matrix Factorization Principles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the basic matrix factorization model, the m * n ratings matrix R is approximately factorized into m * k matrix U and n * k matrix V, as $R \\approx UV^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column of U (or V) is referred to as a latent vector or latent component, whereas each row of U (or V) is referred to as a latent factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Images\\Matrix Factorization Example.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ith row $\\vec{u_{i}}$ of U is referred to as a user factor, and it contains k entries corresponding to the affinity of user i towards the k concepts in the ratings matrix.\n",
    "- For example, in the case above, $\\vec{u_{i}}$ is a 2-dimensional vector containig the affinity of user i towards the history and romance genres in the ratings matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row $\\vec{v_{i}}$ of V is referred to as an item factor, and it respresents the affinity of ith item towards these k concepts. \n",
    "- For example, in the case above, $\\vec{v_{i}}$  conatins the affinity of the item towards the two categories of movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each rating $r_{ij}$ in R can be approximately expressed as a dot product of the ith user factor and jth item factor:\n",
    "$r_{ij} \\approx   \\vec{u_{i}} .  \\vec{v_{i}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the latent factors $\\vec{u_{i}}$ and $\\vec{v_{i}}$ can be viewed as the affinites of the users for k different concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Images\\Matrix Factorization Rating.JPG\" widht = \"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case above, the summation is expressed as \n",
    "<img src = \"Images\\Matrix Factorization Rating Example.JPG\" widht = \"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How can we determine the factor matrices U and V so that the fully specified matrix R matches $UV^{T}$ as closely as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimzation problem with respect to the matrices U and V \n",
    "\n",
    "<img src = \"Images\\Matrix Factorization Optimization.JPG\" width = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variety of gradient descent methods can be used to provide an optimal solution to this factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the set of all user-item pairs (i, j), which are observed in R, be denoted by S. Here i is index of a user and j is index of an item.\n",
    "The set S of observed user-item pair s defined as follows:\n",
    "    \n",
    "<img src = \"Images\\Matrix Factorization Set.JPG\" width = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Images\\Matrix Factorization Optimization 1.JPG\" width = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective function sums up the error only over the observed entries in S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $u_{is}$ and $v_{js}$ are the unknown variables which need to be learned to minimize the objective function. This can be acheived by gradient descent methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Images\\Matrix Factorization Gradient Descent.JPG\" width = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Images\\Matrix Factorization Gradient Descent Algorithm.JPG\" width = \"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a recommendation engine using matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF():\n",
    "\n",
    "    # Initializing the user-movie rating matrix, no. of latent features, alpha and beta.\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    # Initializing user-feature and movie-feature matrix \n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # List of training samples\n",
    "        self.samples = [\n",
    "        (i, j, self.R[i, j])\n",
    "        for i in range(self.num_users)\n",
    "        for j in range(self.num_items)\n",
    "        if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    # Computing total mean squared error\n",
    "    def mse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Ratings for user i and moive j\n",
    "    def get_rating(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_matrix(self):\n",
    "        return mf.b + mf.b_u[:,np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the user item ratings to matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= np.array(ratings.pivot(index = 'user_id', columns ='movie_id', values = 'rating').fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 20 ; error = 296.1260\n",
      "Iteration: 40 ; error = 291.0691\n",
      "Iteration: 60 ; error = 287.6773\n",
      "Iteration: 80 ; error = 282.2684\n",
      "Iteration: 100 ; error = 273.0257\n",
      "\n",
      "P x Q:\n",
      "[[3.84823603 3.35749775 3.22557226 ... 3.29693447 3.42494487 3.3798756 ]\n",
      " [3.87050735 3.31918712 3.11892638 ... 3.3685576  3.50228129 3.45023079]\n",
      " [3.40625431 2.75845158 2.53213911 ... 2.81245311 2.93065692 2.91516687]\n",
      " ...\n",
      " [4.24505526 3.64255364 3.40883074 ... 3.6453093  3.79136316 3.75419681]\n",
      " [4.37021679 3.73638916 3.50187019 ... 3.78169863 3.90826854 3.87378199]\n",
      " [3.59036706 3.21432188 3.04078225 ... 3.26959698 3.35246093 3.33333072]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mf = MF(R, K=20, alpha=0.001, beta=0.01, iterations=100)\n",
    "training_process = mf.train()\n",
    "print()\n",
    "print(\"P x Q:\")\n",
    "print(mf.full_matrix())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "What proportion of items that a user likes were actually recommended\n",
    "<img src = \"Images/Recall.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "Out of all the recommended items, how many did the user actually like?\n",
    "<img src = \"Images/Precision.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE (Root Mean Squared Error)\n",
    "Lesser the RMSE value, better the recommendations\n",
    "<img src = \"Images/RMSE.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above metrics tell us how accurate our recommendations are but they do not focus on the order of recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Reciporcal Rank\n",
    "<img src = \"Images/MRR.jpg\">\n",
    "- Suppose we have recommended 3 movies to a user, say A, B, C in the given order, but the user only liked movie C. As the rank of movie C is 3, the reciprocal rank will be 1/3 <br>\n",
    "- Larger the mean reciprocal rank, better the recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP at k (Mean Average Precision at cutoff k)\n",
    "<img src = \"Images/MAP.jpg\">\n",
    "- Suppose we have made three recommendations [0, 1, 1]. Here 0 means the recommendation is not correct while 1 means that the recommendation is correct. Then the precision at k will be [0, 1/2, 2/3], and the average precision will be (1/3)*(0+1/2+2/3) = 0.38 <br>\n",
    "- Larger the mean average precision, more correct will be the recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDCG (Normalized Discounted Cumulative Gain)\n",
    "- The main difference between MAP and NDCG is that MAP assumes that an item is either of interest (or not), while NDCG gives the relevance score\n",
    "- Let us understand it with an example: suppose out of 10 movies – A to J, we can recommend the first five movies, i.e. A, B, C, D and E while we must not recommend the other 5 movies, i.e., F, G, H, I and J. The recommendation was [A,B,C,D]. So the NDCG in this case will be 1 as the recommended products are relevant for the user\n",
    "- Higher the NDCG value, better the recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
